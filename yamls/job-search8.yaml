apiVersion: batch/v1
kind: Job # Deployment will automatically restart when killed. Use Pod if not needed
metadata:
  labels:
    k8s-app: research
  generateName: amraj-pba-search5k # replace <your_name> with something that identifies you
  namespace: ecewcsng
spec:
  template:
    metadata:
      labels:
        k8s-app: research
    spec:
      restartPolicy: Never
      containers:
      - name: research
        image: amanraj42/tensorflow-gpu-ray:v1.11
        imagePullPolicy: Always
        workingDir: /ceph/amanraj/codes/pba-signet
        command: ["/bin/bash", "scripts/search.sh"] # replace this with your own job execution scripts
        resources:
          requests:
            memory: "48Gi"
            cpu: "16"
            nvidia.com/gpu: 8
          limits:
            memory: "50Gi"
            cpu: "18"
            nvidia.com/gpu: 8 # requesting X GPU
        volumeMounts:
        - mountPath: /dev/shm
          name: dshm
        - mountPath: /ceph
          name: ceph
      volumes:
      - name: dshm
        emptyDir:
          medium: Memory
      - name: ceph
        flexVolume:
          driver: ceph.rook.io/rook
          fsType: ceph
          options:
            clusterNamespace: rook
            fsName: nautilusfs
            path: /ecewcsng
            mountUser: ecewcsng
            mountSecret: ceph-fs-secret
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: gpu-type
                operator: In # Use NotIn for other types
                values:
                - 1080Ti
      nodeSelector:
        kubernetes.io/hostname: clu-fiona2.ucmerced.edu # this node has 8 - 1080-Ti
      tolerations:                                      # use nodes that can't access public internet
        - key: "nautilus.io/science-dmz"
          operator: "Exists"
          effect: "NoSchedule"
